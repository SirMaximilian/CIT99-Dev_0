{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for the Project and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full reset of the camera\n",
    "!echo 'dlinano' | sudo -S systemctl restart nvargus-daemon && printf '\\n'\n",
    "# Check device number\n",
    "#!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms , datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary # for model summary\n",
    "import matplotlib.pyplot as plt # for ploting our data and showing images\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import dataHelper as dH\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from utils import preprocess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.utils import bgr8_to_jpeg\n",
    "from jetcam.csi_camera import CSICamera\n",
    "camera = CSICamera(width=224, height=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Here we are letting pytorch know to use the gpu and we are also importing a pretrained resnet18 model that we are modifying to return only 2 outputs. One for X and one for Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "output_dim = 2\n",
    "# RESNET 18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, output_dim)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "This is the inner workings of resnet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Structure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = os.getcwd() + '/raw_datasets'\n",
    "try:\n",
    "    os.mkdir(path_raw)\n",
    "except OSError:\n",
    "    pass\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " prev_data =  os.scandir(path_raw)\n",
    "h_index = 0\n",
    "prev_count = 0\n",
    "for file in prev_data:\n",
    "    filename, f_ext = os.path.splitext(file.name)\n",
    "    if f_ext == '.jpg':\n",
    "        prev_count += 1\n",
    "        [num] = dH.label_parser(filename, label_num = 1, ext = False)\n",
    "        if num > h_index:\n",
    "            h_index = num\n",
    "print(prev_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "datacollect = True\n",
    "dataSetSize = 150\n",
    "FPScollect = 30\n",
    "SEC_delay = .5\n",
    "\n",
    "\n",
    "loopcounter = 0\n",
    "collectedNum = 0\n",
    "\n",
    "if datacollect:\n",
    "    \n",
    "    image_widget = ipywidgets.Image(format='jpeg')\n",
    "    captured_frame = ipywidgets.Image(format='jpeg')\n",
    "    \n",
    "    # count the index of all images\n",
    "    prev_data =  os.scandir(path_raw)\n",
    "    h_index = 0\n",
    "    prev_count = 0\n",
    "    for file in prev_data:\n",
    "        filename, f_ext = os.path.splitext(file.name)\n",
    "        if f_ext == '.jpg':\n",
    "            prev_count += 1\n",
    "            [num] = dH.label_parser(filename, label_num = 1, ext = False)\n",
    "            if num > h_index:\n",
    "                h_index = num\n",
    "    \n",
    "    collectedNum = prev_count\n",
    "    h_index += 1\n",
    "    \n",
    "    camera.unobserve_all()\n",
    "    print('Get Ready!')\n",
    "    frame = camera.read()\n",
    "    image_widget.value = bgr8_to_jpeg(frame)\n",
    "    captured_frame.value = bgr8_to_jpeg(frame)\n",
    "    #plt.imshow(bgr8_to_jpeg(frame))\n",
    "    time.sleep(6)\n",
    "    display(ipywidgets.HBox([image_widget, captured_frame]))\n",
    "    print('Begin!')\n",
    "    \n",
    "    while True:\n",
    "        if collectedNum == dataSetSize:\n",
    "            break\n",
    "        frame = camera.read()\n",
    "        #plt.imshow(frame)\n",
    "        image_widget.value = bgr8_to_jpeg(frame)\n",
    "        if loopcounter % (FPScollect * SEC_delay) == 0:\n",
    "            # write raw images to file \n",
    "            captured_frame.value = bgr8_to_jpeg(frame)\n",
    "            dH.write_raw_frame(path_raw, frame, h_index)\n",
    "            h_index += 1\n",
    "            collectedNum += 1\n",
    "        loopcounter += 1\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labeling\n",
    "\n",
    "An I oop... data is labeled on aonther PC because some libraries are broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "REBUILD = True\n",
    "\n",
    "\n",
    "path_labeled = os.getcwd() + '/labeled_datasets'\n",
    "data = os.scandir(path_labeled)\n",
    "\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(1,1,1)\n",
    "#plt.axis(\"off\")\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "fill = np.zeros((224,224,2))\n",
    "\n",
    "if REBUILD:\n",
    "    training_data = []\n",
    "    for i in data:\n",
    "        if '.jpg' in i.name:\n",
    "            img = cv2.imread(path_labeled +'/'+ i.name)\n",
    "            img = PIL.Image.fromarray(img)\n",
    "            [imgnum, x, y] = dH.label_parser(path_labeled +'/'+ i.name)\n",
    "            #print(f'{imgnum},{x},{y}')\n",
    "            #imgplot = plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            x = 2.0 * (x / 224 - 0.5)\n",
    "            y = 2.0 * (y / 224 - 0.5)\n",
    "            \n",
    "            img = TRANSFORMS(img)\n",
    "            training_data.append([np.array(img),np.array([x,y])])\n",
    "    np.random.shuffle(training_data)\n",
    "    np.save('training_data.npy', training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "TRAIN = True\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "training_data = np.load('training_data.npy', allow_pickle=True)\n",
    "training_img = torch.Tensor([i[0] for i in training_data]).view(-1,3,224,224).to(device)\n",
    "training_label = torch.Tensor([i[1] for i in training_data]).view(-1,2).to(device)\n",
    "\n",
    "if False:\n",
    "    model = torch.load('test_run_1')\n",
    "\n",
    "if TRAIN:\n",
    "    model = model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        # randomize each epoch\n",
    "        #rand_idx = torch.randperm(len(training_data))\n",
    "        \n",
    "        for i in range(0, len(training_data), BATCH_SIZE):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            #output = model(training_img[rand_idx[i:i+BATCH_SIZE]].view(-1,3,224,224))\n",
    "            output = model(training_img[i:i+BATCH_SIZE].view(-1,3,224,224))\n",
    "            \n",
    "            #computed_output = 224 * (output / 2.0 + 0.5)\n",
    "            #processed_labels = 2.0 * (training_label[rand_idx[i:i+BATCH_SIZE]].view(-1,2) / 224 - 0.5)\n",
    "            #processed_labels = 2.0 * (training_label[i:i+BATCH_SIZE].view(-1,2) / 224 - 0.5)\n",
    "            \n",
    "            loss = loss_func(output,training_label[i:i+BATCH_SIZE].view(-1,2)) #computed_output,training_label[rand_idx[i:i+BATCH_SIZE]].view(-1,2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #break\n",
    "        #break\n",
    "        #print(output)\n",
    "        #print(processed_labels)\n",
    "        print(loss)\n",
    "    '''\n",
    "    print('testing')\n",
    "    print(output)\n",
    "    print(computed_output)\n",
    "    #plt.imshow(check.cpu().view(224,224,3).numpy().astype(int))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'test_run_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 44\n",
    "o = model(training_img[test_idx].view(-1,3,224,224))\n",
    "c_output = 224 * (o / 2.0 + 0.5)\n",
    "L = training_label[test_idx]\n",
    "L = 224 * (L / 2.0 + 0.5)\n",
    "print(c_output)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Eval = True\n",
    "camera.running = False\n",
    "if Eval:\n",
    "    model = model.eval()\n",
    "    camera.unobserve_all()\n",
    "    eval_iwdget = ipywidgets.Image(format='jpeg')\n",
    "    \n",
    "    image = camera.read()\n",
    "    input_tensor = torch.Tensor(image).view(-1,3,224,224).to(device)\n",
    "    output = model(input_tensor).detach().cpu().numpy().flatten()\n",
    "    #print(224 * (output / 2.0 + 0.5))\n",
    "    image = cv2.circle(image, (int(224 * (output[0] / 2.0 + 0.5)), int(224 * (output[1] / 2.0 + 0.5))), 8, (255, 0, 0), 3)\n",
    "    eval_iwdget.value = bgr8_to_jpeg(image)\n",
    "    display(eval_iwdget)\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        image = camera.read()\n",
    "        #input_tensor = torch.Tensor(image).view(-1,3,224,224).to(device)\n",
    "        processed = preprocess(image)\n",
    "        output = model(processed).detach().cpu().numpy().flatten()\n",
    "        image = cv2.circle(image, (int(224 * (output[0] / 2.0 + 0.5)), int(224 * (output[1] / 2.0 + 0.5))), 8, (255, 0, 0), 3)\n",
    "        eval_iwdget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "    \n",
    "    #prediction = cv2.circle(prediction, (x, y), 8, (255, 0, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess\n",
    "image = camera.read()\n",
    "processed = preprocess(image)\n",
    "p = processed.cpu().numpy()\n",
    "np.reshape(p,(224,224,3))\n",
    "#imgplot = plt.imshow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
